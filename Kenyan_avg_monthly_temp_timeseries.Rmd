---
title: "Kenyan Climate Data Timeseries Analysis and Prediction"
author: "Kelvin Mwaka Muia"
output: html_notebook
---

# Data importation and initial inspection.   

```{r setup, include=FALSE}
rm(list=ls())#clear R work space for every rerun
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      message = FALSE,
                      out.width = "150%",
                      out.height = "150%",
                      fig.align = "center")
# silent package loading
packages <- c("tsibble", "fpp3", "gridExtra","prophet",
              "janitor","knitr","forcats","forecast",
              "reticulate","tensorflow", "lubridate", 
              "ggplot2","keras","tidyverse","formatR",
              "ggthemes","ggpubr", "scales","tidymodels")
# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
    install.packages(packages[!installed_packages])}
# Packages loading
invisible(lapply(packages, library, character.only = TRUE))
```


```{r}
#load Kenyan average monthly temperatures from 1991 to 2016
kenyan_temp <- read.csv("kenya-climate-data-1991-2016-temp-degress-celcius.csv")
kenyan_rain <- read.csv("kenya-climate-data-1991-2016-rainfallmm.csv")
#view structure
glimpse(kenyan_temp)
glimpse(kenyan_rain)
```
    
## Cleaning the climate data

```{r}
#clean column names using janitor
kenyan_temp <- clean_names(kenyan_temp)
kenyan_rain <- clean_names(kenyan_rain)
#remove the "Average" part from the monthly names
kenyan_temp <- kenyan_temp |>
  mutate(month = gsub("Average", "", month_average)) |>
  mutate(month = gsub("\\s", "", month)) |>
  select(year,month,temperature_celsius)
#concatenate the year and month variables to form a year-month variable
kenyan_temp$year_month <- paste(kenyan_temp$year, kenyan_temp$month, sep="-")
#select the necessary columns and convert to tsibble
kenyan_temp <- kenyan_temp |> 
  mutate(month = yearmonth(year_month)) |>
  select(month, temperature_celsius) |>
  as_tsibble()
head(kenyan_temp)
```



```{r}
#explore and visualize the data
kenyan_temp |>
  autoplot(temperature_celsius) +
  labs(y = "Average temperature",
       title = "Monthly average temperature")
```
       

```{r}
#visualize the seasonality, and subseries
kenyan_temp |> 
  gg_season(temperature_celsius, period="year") 
kenyan_temp |>
  gg_subseries(temperature_celsius)
```
     
     
     
## Data Preparation for timeseries modeling.  

```{r}
#partition the data into training set (up to 1999)
train_tsibble <- kenyan_temp |>
  filter(year(month) <= 2011)
```


# Exponential Smoothing (SES)

## Auto ETS

```{r}
#automatic ETS model selection
ets_auto <- train_tsibble %>%
  model(ETS(temperature_celsius))
report(ets_auto)
```
        
> 1. ETS(M,N,M) (the model suggested by auto ETS):

- Accounts for multiplicative errors, meaning the size of the errors is proportional to the level of the series.    


### Auto-ETS-model Fitted vs actual temperature values

```{r}
#augment auto ETS model
ets_auto_data <- augment(ets_auto) |>
  select(temperature_celsius, .resid, .fitted)
ets_auto_data |>
  ggplot() +
  geom_line(aes(x = month, y = temperature_celsius, color = "Actual")) +
  geom_line(aes(x = month, y = .fitted, color = "Fitted")) +
  labs(y = "Fitted", x = "Month",
       title = "Actual temperature (celsius) vs ETS (MNM-auto) fitted values") +
  geom_abline(intercept = 0, slope = 1) +
  scale_color_manual(values = c("Actual" = "blue", "Fitted" = "red"))

```

  


## ETS(M,A,M): Additive trend, multiplicative errors.     


```{r}
#ETS MAM
ets_MAM <- train_tsibble %>%
  model(ETS(temperature_celsius ~ error("M") + trend("A") + season("M")))
report(ets_MAM)

```
    
### MAM-ETS-model Fitted vs actual temperature values

```{r}
#augment auto ETS model
ets_MAM_data <- augment(ets_MAM) |>
  select(temperature_celsius, .resid, .fitted)
ets_MAM_data |>
  ggplot() +
  geom_line(aes(x = month, y = temperature_celsius, color = "Actual")) +
  geom_line(aes(x = month, y = .fitted, color = "Fitted")) +
  labs(y = "Fitted", x = "Month",
       title = "Actual temperature (celsius) vs ETS (MAM) fitted values") +
  geom_abline(intercept = 0, slope = 1) +
  scale_color_manual(values = c("Actual" = "blue", "Fitted" = "red"))

```



## ETS(M,Ad,M): Damped additive trend, multiplicative errors.


```{r}
#ETS MAM
ets_MAdM <- train_tsibble %>%
  model(ETS(temperature_celsius ~ error("M") + trend("Ad") + season("M")))
report(ets_MAdM)

```
    
### MAdM-ETS-model Fitted vs actual temperature values

```{r}
#augment auto ETS model
ets_MAdM_data <- augment(ets_MAdM) |>
  select(temperature_celsius, .resid, .fitted)
ets_MAdM_data |>
  ggplot() +
  geom_line(aes(x = month, y = temperature_celsius, color = "Actual")) +
  geom_line(aes(x = month, y = .fitted, color = "Fitted")) +
  labs(y = "Fitted", x = "Month",
       title = "Actual temperature (celsius) vs ETS (MAdM) fitted values") +
  geom_abline(intercept = 0, slope = 1) +
  scale_color_manual(values = c("Actual" = "blue", "Fitted" = "red"))

```




## ETS(M,N,A): Multiplicative seasonality, multiplicative errors.

```{r}
#ETS MNA
ets_MNA <- train_tsibble %>%
  model(ETS(temperature_celsius ~ error("M") + trend("N") + season("A")))
report(ets_MNA)
```
     
### MAdM-ETS-model Fitted vs actual temperature values

```{r}
#augment auto ETS model
ets_MNA_data <- augment(ets_MNA) |>
  select(temperature_celsius, .resid, .fitted)
ets_MNA_data |>
  ggplot() +
  geom_line(aes(x = month, y = temperature_celsius, color = "Actual")) +
  geom_line(aes(x = month, y = .fitted, color = "Fitted")) +
  labs(y = "Fitted", x = "Month",
       title = "Actual temperature (celsius) vs ETS (MNA) fitted values") +
  geom_abline(intercept = 0, slope = 1) +
  scale_color_manual(values = c("Actual" = "blue", "Fitted" = "red"))

```



## ETS(A,N,N); additive errors (errors are independent of the level of the series)

```{r}
#ETS ANN
ets_ANN <- train_tsibble %>%
  model(ETS(temperature_celsius ~ error("A") + trend("N") + season("N")))
report(ets_ANN)

```

```{r}
#augment auto ETS model
ets_ANN_data <- augment(ets_ANN) |>
  select(temperature_celsius, .resid, .fitted)
ets_ANN_data |>
  ggplot() +
  geom_line(aes(x = month, y = temperature_celsius, color = "Actual")) +
  geom_line(aes(x = month, y = .fitted, color = "Fitted")) +
  labs(y = "Fitted", x = "Month",
       title = "Actual temperature (celsius) vs ETS (ANN) fitted values") +
  geom_abline(intercept = 0, slope = 1) +
  scale_color_manual(values = c("Actual" = "blue", "Fitted" = "red"))

```






## Create date data.  

```{r}
#mapping of abbreviated month names to full month names
month_mapping <- c( "Jan" = "January","Feb" = "February","Mar" = "March",
                    "Apr" = "April","May" = "May","Jun" = "June",
                    "Jul" = "July","Aug" = "August","Sep" = "September",
                    "Oct" = "October","Nov" = "November","Dec" = "December")
#converting the month column to a factor and map it to full month names
kenyan_temp <- kenyan_temp |>
  mutate(month = fct_recode(as.factor(month), !!!month_mapping))
#convert the year and month_full columns to a Date format
kenyan_temp <- kenyan_temp |>
  mutate(date = ymd(paste(year, month, "01", sep = "-")))|>
  select(date, temperature_celsius)
#create a new data structure with both temperature and rain features
kenyan_climate <- kenyan_temp
kenyan_climate$rainfall_mm <- kenyan_rain$rainfall_mm

write.csv(kenyan_climate, "Kenyan_climate_timeseries.csv")
```


## Timeseries analysis.   


```{r}
#create a time series object using the temperature_celsius column
temp_ts <- ts(kenyan_climate$temperature_celsius, 
              start = min(kenyan_climate$date), 
              frequency = 12)
rain_ts <- ts(kenyan_climate$rainfall_mm, 
              start = min(kenyan_climate$date), 
              frequency = 12)
#viewthe time series object
print(temp_ts)
print(rain_ts)
```



```{r}
#simple visualizations
autoplot(temp_ts)
autoplot(rain_ts)
```
     



    
## Data Preparation for timeseries modeling.    


```{r}
#preparing the data
#splitting the data into training and test sets
train_percentage <- 0.8  # 80% for training, 20% for testing
train_size <- floor(train_percentage * length(temp_ts))
train_data <- temp_ts[1:train_size]
test_data <- temp_ts[(train_size + 1):length(temp_ts)]
#scaling the data to improve model performance
min_value <- min(temp_ts)
max_value <- max(temp_ts)
scaled_train_data <- scale(train_data, 
                           center = min_value, 
                           scale = max_value - min_value)
scaled_test_data <- scale(test_data, 
                          center = min_value, 
                          scale = max_value - min_value)
```


### ARIMA modeling.     

```{r}
# Prepare the data for ARIMA modeling
arima_data <- ts(kenyan_climate$temperature_celsius[1:312], start = min(kenyan_climate$date), frequency = 12)
# Fit the ARIMA model
arima_model <- auto.arima(arima_data)
# Generate predictions using the ARIMA model
arima_predictions <- forecast(arima_model, h = length(test_data))$mean
# Plot the predictions and ground truth
par(mfrow=c(1,2))
plot(test_data, type = 'l', 
     col = 'blue', xlab = 'Time', ylab = 'Temperature (Celsius)', 
     main = 'Ground Truth')
plot(arima_predictions, type = 'l', col = 'red',xlab = 'Time', main="ARIMA Predictions")
```


### PROPHET model.

   
```{r}
# Prepare the data
prophet_data <- data.frame(ds = kenyan_climate$date, 
                           y = kenyan_climate$temperature_celsius)
#create the Prophet model
model <- prophet(prophet_data)
# Fit the model to the data
#model <- fit.prophet(model, prophet_data)
# Create future dates for forecasting
future_dates <- make_future_dataframe(model, periods = 12, freq = "month")
# Generate predictions using the Prophet model
prophet_predictions <- predict(model, future_dates)$yhat
par(mfrow=c(2,1))
# Plot the predictions and ground truth
plot(prophet_data$ds, prophet_data$y, type = 'l', 
     col = 'blue', xlab = 'Time', ylab = "Temperature (Celsius)", 
     main = "Ground Truth")
plot(future_dates$ds, prophet_predictions, type = 'l', col = 'red',
     xlab = 'Time', main = "Prophet Predictions")
```


### LSTM modeling. 

```{r}
#creating an LSTM model
model <- keras_model_sequential()
model |>
  layer_lstm(units = 50, input_shape = c(1, 1)) |>
  layer_dense(units = 1)
#compiling the model
model |> compile(
  loss = 'mean_squared_error',
  optimizer = optimizer_adam())
#fitting the model to the training data
history <- model |> fit(
  x = array_reshape(scaled_train_data, c(length(scaled_train_data), 1, 1)),
  y = scaled_train_data,
  epochs = 50,
  batch_size = 1,
  verbose = 2)
```


```{r}
# Make predictions on the test data
scaled_predictions <- model |> 
  predict(array_reshape(scaled_test_data,c(length(scaled_test_data), 1, 1)))
#un-scale the predicted temperature values
predictions <- scaled_predictions * (max_value - min_value) + min_value
par(mfrow=c(1,2))
# Plot the predictions and ground truth
plot(test_data, type = 'l', col = 'blue', 
     xlab = 'Time', ylab = 'Temperature (Celsius)', 
     main = 'Ground Truth')
plot(predictions, type = 'l', col = 'red', 
     xlab = 'Time', main = 'LSTM Predictions')
```


       







